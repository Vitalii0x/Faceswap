{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cellular-michael",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda/envs/faceshift_env/lib/python3.8/site-packages/kornia/augmentation/augmentation.py:1830: DeprecationWarning: GaussianBlur is no longer maintained and will be removed from the future versions. Please use RandomGaussianBlur instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import time\n",
    "\n",
    "from utils.inference.image_processing import crop_face\n",
    "from utils.inference.video_processing import read_video, get_final_video_frame, add_audio_from_another_video\n",
    "from utils.inference.core import model_inference\n",
    "\n",
    "from network.AEI_Net import AEI_Net\n",
    "from coordinate_reg.image_infer import Handler\n",
    "from insightface_func.face_detect_crop_single import Face_detect_crop\n",
    "from arcface_model.iresnet import iresnet100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-exploration",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Face_detect_crop(name='antelope', root='./insightface_func/models')\n",
    "app.prepare(ctx_id= 0, det_thresh=0.6, det_size=(640,640))\n",
    "\n",
    "# основная модель для генерации\n",
    "G = AEI_Net(c_id=512)\n",
    "G.eval()\n",
    "G.load_state_dict(torch.load('weights/G_0_035000_init_arch_arcface2.pth', map_location=torch.device('cpu')))\n",
    "G = G.cuda()\n",
    "G = G.half()\n",
    "\n",
    "# модель arcface для того, чтобы достать эмбеддинг лица\n",
    "netArc = iresnet100(fp16=False)\n",
    "netArc.load_state_dict(torch.load('arcface_model/backbone.pth'))\n",
    "netArc=netArc.cuda()\n",
    "netArc.eval()\n",
    "\n",
    "# модель, которая позволяет находить точки лица\n",
    "handler = Handler('./coordinate_reg/model/2d106det', 0, ctx_id=0, det_size=640)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-consensus",
   "metadata": {},
   "source": [
    "### Set here path to source image and video for faceswap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "choose not really long videos, coz it can take a lot of time othervise \n",
    "choose source image as a photo -- preferable a selfie of a person\n",
    "\"\"\"\n",
    "\n",
    "path_to_video = 'examples/videos/dora_short.mp4'\n",
    "source_full = cv2.imread('examples/images/elon_musk.jpg')\n",
    "OUT_VIDEO_NAME = \"examples/results/elon2dora.mp4\"\n",
    "crop_size = 224 # don't change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check, if we can detect face on the source image\n",
    "\n",
    "try:\n",
    "    source = crop_face(source_full, app, crop_size)[0]\n",
    "    source = source[:, :, ::-1]\n",
    "    print(\"Everything is ok!\")\n",
    "except TypeError:\n",
    "    print(\"Bad source image. Choose another one.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-maryland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read video\n",
    "\n",
    "full_frames, fps = read_video(path_to_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-prisoner",
   "metadata": {},
   "source": [
    "### Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TIME = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_frames, crop_frames, full_frames, tfm_array = model_inference(full_frames,\n",
    "                                                                    source,\n",
    "                                                                    [netArc],\n",
    "                                                                    G,\n",
    "                                                                    app, \n",
    "                                                                    crop_size=crop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_final_video_frame(final_frames,\n",
    "                      crop_frames,\n",
    "                      full_frames,\n",
    "                      tfm_array,\n",
    "                      OUT_VIDEO_NAME,\n",
    "                      fps, \n",
    "                      handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-oxide",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_audio_from_another_video(path_to_video, OUT_VIDEO_NAME, \"audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-marketing",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Full pipeline took {time.time() - START_TIME}')\n",
    "print(f\"Video saved with path {OUT_VIDEO_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-costs",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-breeding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-laundry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-limitation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-darkness",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fs_env",
   "language": "python",
   "name": "fs_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
