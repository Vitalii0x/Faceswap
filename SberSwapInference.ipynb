{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "joined-nelson",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda/envs/faceshift_env/lib/python3.8/site-packages/kornia/augmentation/augmentation.py:1830: DeprecationWarning: GaussianBlur is no longer maintained and will be removed from the future versions. Please use RandomGaussianBlur instead.\n",
      "  warnings.warn(\n",
      "/home/jovyan/final_repo/sber-swap/models/networks/normalization.py:68: DeprecationWarning: invalid escape sequence \\D\n",
      "  parsed = re.search('spade(\\D+)(\\d)x\\d', config_text)\n",
      "/home/jovyan/final_repo/sber-swap/utils/inference/util.py:165: DeprecationWarning: invalid escape sequence \\d\n",
      "  return [atoi(c) for c in re.split('(\\d+)', text)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "\n",
    "from utils.inference.image_processing import crop_face\n",
    "from utils.inference.video_processing import read_video, get_final_video_frame, add_audio_from_another_video, face_enhancement\n",
    "from utils.inference.core import model_inference\n",
    "\n",
    "from network.AEI_Net import AEI_Net\n",
    "from coordinate_reg.image_infer import Handler\n",
    "from insightface_func.face_detect_crop_single import Face_detect_crop\n",
    "from arcface_model.iresnet import iresnet100\n",
    "from models.pix2pix_model import Pix2PixModel\n",
    "from models.config_sr import TestOptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-polymer",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pregnant-grant",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input mean and std: 127.5 127.5\n",
      "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
      "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
      "set det-size: (640, 640)\n",
      "loading ./coordinate_reg/model/2d106det 0\n",
      "input mean and std: 127.5 127.5\n",
      "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
      "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
      "set det-size: (640, 640)\n",
      "Network [LIPSPADEGenerator] was created. Total number of parameters: 72.2 million. To see the architecture, do print(network).\n",
      "Load checkpoint from path:  weights/10_net_G.pth\n"
     ]
    }
   ],
   "source": [
    "app = Face_detect_crop(name='antelope', root='./insightface_func/models')\n",
    "app.prepare(ctx_id= 0, det_thresh=0.6, det_size=(640,640))\n",
    "\n",
    "# main model for generation\n",
    "G = AEI_Net(c_id=512)\n",
    "G.eval()\n",
    "G.load_state_dict(torch.load('weights/G_0_035000_init_arch_arcface2.pth', map_location=torch.device('cpu')))\n",
    "G = G.cuda()\n",
    "G = G.half()\n",
    "\n",
    "# arcface model to get face embedding\n",
    "netArc = iresnet100(fp16=False)\n",
    "netArc.load_state_dict(torch.load('arcface_model/backbone.pth'))\n",
    "netArc=netArc.cuda()\n",
    "netArc.eval()\n",
    "\n",
    "# model to get face landmarks\n",
    "handler = Handler('./coordinate_reg/model/2d106det', 0, ctx_id=0, det_size=640)\n",
    "\n",
    "# model to make superres of face, set use_sr=True if you want to use super resolution or use_sr=False if you don't\n",
    "use_sr = False\n",
    "if use_sr:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    opt = TestOptions()\n",
    "    #opt.which_epoch ='10_7'\n",
    "    model = Pix2PixModel(opt)\n",
    "    model.netG.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-match",
   "metadata": {},
   "source": [
    "### Set here path to source image and video for faceswap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tracked-memorial",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "choose not really long videos, coz it can take a lot of time othervise \n",
    "choose source image as a photo -- preferable a selfie of a person\n",
    "\"\"\"\n",
    "\n",
    "path_to_video = 'examples/videos/dora_short.mp4'\n",
    "source_full = cv2.imread('examples/images/elon_musk.jpg')\n",
    "OUT_VIDEO_NAME = \"examples/results/elon2dora.mp4\"\n",
    "crop_size = 224 # don't change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "virtual-correlation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is ok!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# check, if we can detect face on the source image\n",
    "\n",
    "try:\n",
    "    source = crop_face(source_full, app, crop_size)[0]\n",
    "    source = source[:, :, ::-1]\n",
    "    print(\"Everything is ok!\")\n",
    "except TypeError:\n",
    "    print(\"Bad source image. Choose another one.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "individual-planet",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# read video\n",
    "\n",
    "full_frames, fps = read_video(path_to_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-rolling",
   "metadata": {},
   "source": [
    "### Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adjacent-personal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "START_TIME = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "vocal-facility",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "100%|██████████| 262/262 [00:02<00:00, 102.30it/s]\n",
      "/home/jovyan/conda/envs/faceshift_env/lib/python3.8/site-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "262it [00:00, 4874.78it/s]\n",
      "100%|██████████| 5/5 [00:06<00:00,  1.39s/it]\n",
      "100%|██████████| 262/262 [00:00<00:00, 542135.00it/s]\n"
     ]
    }
   ],
   "source": [
    "final_frames, crop_frames, full_frames, tfm_array = model_inference(full_frames,\n",
    "                                                                    source,\n",
    "                                                                    [netArc],\n",
    "                                                                    G,\n",
    "                                                                    app, \n",
    "                                                                    crop_size=crop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "recovered-council",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "14it [00:07,  1.86it/s]\n"
     ]
    }
   ],
   "source": [
    "if use_sr:\n",
    "    final_frames = face_enhancement(final_frames, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "grave-nancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "  0%|          | 0/262 [00:00<?, ?it/s]/home/jovyan/conda/envs/faceshift_env/lib/python3.8/site-packages/kornia/geometry/transform/imgwarp.py:184: UserWarning: The align_corners default value has been changed. By default now is set True in order to match cv2.warpAffine. In case you want to keep your previous behaviour set it to False. This warning will disappear in kornia > v0.6.\n",
      "  warnings.warn(message)\n",
      "/home/jovyan/final_repo/sber-swap/utils/inference/video_processing.py:199: UserWarning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorIterator.cpp:918.)\n",
      "  final = (mask_t*swap_t + (1-mask_t)*frame).type(torch.uint8).squeeze().permute(1,2,0).cpu().detach().numpy()\n",
      "100%|██████████| 262/262 [00:05<00:00, 47.31it/s]\n"
     ]
    }
   ],
   "source": [
    "get_final_video_frame(final_frames,\n",
    "                      crop_frames,\n",
    "                      full_frames,\n",
    "                      tfm_array,\n",
    "                      OUT_VIDEO_NAME,\n",
    "                      fps, \n",
    "                      handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "emerging-toolbox",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "add_audio_from_another_video(path_to_video, OUT_VIDEO_NAME, \"audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "color-conditions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full pipeline took 26.246086597442627\n",
      "Video saved with path examples/results/elon2dora.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "print(f'Full pipeline took {time.time() - START_TIME}')\n",
    "print(f\"Video saved with path {OUT_VIDEO_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-vitamin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-debate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-sperm",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-uganda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-macro",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsh",
   "language": "python",
   "name": "fsh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
